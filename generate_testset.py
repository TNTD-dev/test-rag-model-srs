import os
import glob
import json
import google.generativeai as genai
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()

# Config
DATA_DIR = "./data/AI Knowledge Base WMS"
OUTPUT_FILE = "./data/synthetic_testset.json"
NUM_QUESTIONS_PER_FILE = 2

# Init Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel('gemini-2.5-flash-lite')

def generate_questions(text, filename):
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia t·∫°o d·ªØ li·ªáu ki·ªÉm th·ª≠.
    D·ª±a tr√™n vƒÉn b·∫£n sau (ƒë∆∞·ª£c tr√≠ch t·ª´ file '{filename}'), h√£y ƒë·∫∑t {NUM_QUESTIONS_PER_FILE} c√¢u h·ªèi c·ª• th·ªÉ m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ h·ªèi.
    
    Y√äU C·∫¶U:
    - C√¢u h·ªèi ph·∫£i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn n·ªôi dung vƒÉn b·∫£n.
    - C√¢u h·ªèi ph·∫£i ƒë√≥ng vai l√† Business Analyst ho·∫∑c PM h·ªèi v·ªÅ nghi·ªáp v·ª•.
    - Output tr·∫£ v·ªÅ d·∫°ng JSON List thu·∫ßn t√∫y: ["C√¢u h·ªèi 1", "C√¢u h·ªèi 2", ...]
    
    VƒÇN B·∫¢N:
    {text[:4000]} (c·∫Øt ng·∫Øn ƒë·ªÉ v·ª´a context)
    """
    try:
        response = model.generate_content(prompt)
        text_resp = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text_resp)
    except Exception as e:
        print(f"Error generating questions for {filename}: {e}")
        return []

def main():
    print(f"üöÄ Starting Synthetic Testset Generation from {DATA_DIR}...")
    dataset = []
    
    # Get all .md files
    files = glob.glob(os.path.join(DATA_DIR, "*.md"))
    
    if not files:
        print(f"‚ùå No markdown files found in {DATA_DIR}")
        return

    for filepath in tqdm(files, desc="Processing files"):
        filename = os.path.basename(filepath)
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()
                
            if not content.strip():
                continue
                
            questions = generate_questions(content, filename)
            
            for q in questions:
                dataset.append({
                    "question": q,
                    "ground_truth_source": filename,
                    "ground_truth_content_snippet": content[:200]
                })
                
        except Exception as e:
            print(f"Skipping {filename}: {e}")

    # Save
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
        
    print(f"\n‚úÖ Generated {len(dataset)} pairs. Saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
